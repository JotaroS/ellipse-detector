{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "turning an image into array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_img = load_img('./cropped/0.jpg', color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=128x128 at 0x2725A3C4D60>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_img_array = img_to_array(temp_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_img_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset():\n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    # X\n",
    "    for f in glob.glob('./cropped/*.jpg')[:100]:\n",
    "        temp_img = load_img(f, color_mode='grayscale')\n",
    "        arr      = img_to_array(temp_img)\n",
    "        X.append(arr)\n",
    "    X = np.asarray(X)\n",
    "    X = X.astype('float32')\n",
    "    X = X / 255.0\n",
    "    \n",
    "    # Y\n",
    "    with open('labels.json') as f:\n",
    "        data = json.load(f)\n",
    "    for d in data[:100]:\n",
    "        y = [d['center'][0]/128.0, d['center'][1]/128.0, d['radius']/128.0]\n",
    "        Y.append(y)\n",
    "    Y = np.asarray(Y)\n",
    "    Y = Y.astype('float32')\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = generate_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         ...,\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         ...,\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         ...,\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         ...,\n",
       "         [0.58431375],\n",
       "         [0.4117647 ],\n",
       "         [0.41568628]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         ...,\n",
       "         [0.2901961 ],\n",
       "         [0.2901961 ],\n",
       "         [0.49803922]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         ...,\n",
       "         [0.36862746],\n",
       "         [0.2784314 ],\n",
       "         [0.41568628]]],\n",
       "\n",
       "\n",
       "       [[[0.27058825],\n",
       "         [0.27058825],\n",
       "         [0.27058825],\n",
       "         ...,\n",
       "         [0.1764706 ],\n",
       "         [0.17254902],\n",
       "         [0.17254902]],\n",
       "\n",
       "        [[0.27058825],\n",
       "         [0.27058825],\n",
       "         [0.27058825],\n",
       "         ...,\n",
       "         [0.1764706 ],\n",
       "         [0.17254902],\n",
       "         [0.17254902]],\n",
       "\n",
       "        [[0.27450982],\n",
       "         [0.27450982],\n",
       "         [0.27450982],\n",
       "         ...,\n",
       "         [0.1764706 ],\n",
       "         [0.17254902],\n",
       "         [0.17254902]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.87058824],\n",
       "         [0.87058824],\n",
       "         [0.87058824],\n",
       "         ...,\n",
       "         [0.72156864],\n",
       "         [0.7137255 ],\n",
       "         [0.70980394]],\n",
       "\n",
       "        [[0.92941177],\n",
       "         [0.91764706],\n",
       "         [0.90588236],\n",
       "         ...,\n",
       "         [0.72156864],\n",
       "         [0.7176471 ],\n",
       "         [0.7137255 ]],\n",
       "\n",
       "        [[0.9137255 ],\n",
       "         [0.9019608 ],\n",
       "         [0.8901961 ],\n",
       "         ...,\n",
       "         [0.72156864],\n",
       "         [0.7176471 ],\n",
       "         [0.7137255 ]]],\n",
       "\n",
       "\n",
       "       [[[0.9137255 ],\n",
       "         [0.7529412 ],\n",
       "         [0.98039216],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.58431375],\n",
       "         [0.34117648]],\n",
       "\n",
       "        [[0.6313726 ],\n",
       "         [0.5764706 ],\n",
       "         [0.61960787],\n",
       "         ...,\n",
       "         [0.0627451 ],\n",
       "         [0.49019608],\n",
       "         [0.12941177]],\n",
       "\n",
       "        [[0.41568628],\n",
       "         [0.6784314 ],\n",
       "         [0.41960785],\n",
       "         ...,\n",
       "         [0.13333334],\n",
       "         [0.16470589],\n",
       "         [0.43137255]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.3372549 ],\n",
       "         [0.37254903],\n",
       "         [0.33333334],\n",
       "         ...,\n",
       "         [0.43529412],\n",
       "         [0.41568628],\n",
       "         [0.4117647 ]],\n",
       "\n",
       "        [[0.38039216],\n",
       "         [0.4392157 ],\n",
       "         [0.5411765 ],\n",
       "         ...,\n",
       "         [0.52156866],\n",
       "         [0.5254902 ],\n",
       "         [0.31764707]],\n",
       "\n",
       "        [[0.47058824],\n",
       "         [0.47843137],\n",
       "         [0.3764706 ],\n",
       "         ...,\n",
       "         [0.25490198],\n",
       "         [0.16470589],\n",
       "         [0.3529412 ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.93333334],\n",
       "         [0.93333334],\n",
       "         [0.93333334],\n",
       "         ...,\n",
       "         [0.7372549 ],\n",
       "         [0.7607843 ],\n",
       "         [0.7882353 ]],\n",
       "\n",
       "        [[0.92941177],\n",
       "         [0.92941177],\n",
       "         [0.93333334],\n",
       "         ...,\n",
       "         [0.7254902 ],\n",
       "         [0.7490196 ],\n",
       "         [0.76862746]],\n",
       "\n",
       "        [[0.92156863],\n",
       "         [0.9254902 ],\n",
       "         [0.9254902 ],\n",
       "         ...,\n",
       "         [0.7137255 ],\n",
       "         [0.7294118 ],\n",
       "         [0.74509805]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.47058824],\n",
       "         [0.47058824],\n",
       "         [0.4745098 ],\n",
       "         ...,\n",
       "         [0.14509805],\n",
       "         [0.14901961],\n",
       "         [0.16078432]],\n",
       "\n",
       "        [[0.49803922],\n",
       "         [0.48235294],\n",
       "         [0.4627451 ],\n",
       "         ...,\n",
       "         [0.14117648],\n",
       "         [0.14117648],\n",
       "         [0.15686275]],\n",
       "\n",
       "        [[0.5254902 ],\n",
       "         [0.49803922],\n",
       "         [0.47058824],\n",
       "         ...,\n",
       "         [0.13725491],\n",
       "         [0.14117648],\n",
       "         [0.15294118]]],\n",
       "\n",
       "\n",
       "       [[[0.53333336],\n",
       "         [0.53333336],\n",
       "         [0.53333336],\n",
       "         ...,\n",
       "         [0.654902  ],\n",
       "         [0.654902  ],\n",
       "         [0.654902  ]],\n",
       "\n",
       "        [[0.53333336],\n",
       "         [0.53333336],\n",
       "         [0.53333336],\n",
       "         ...,\n",
       "         [0.654902  ],\n",
       "         [0.6509804 ],\n",
       "         [0.6509804 ]],\n",
       "\n",
       "        [[0.53333336],\n",
       "         [0.53333336],\n",
       "         [0.53333336],\n",
       "         ...,\n",
       "         [0.64705884],\n",
       "         [0.64705884],\n",
       "         [0.64705884]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.62352943],\n",
       "         [0.62352943],\n",
       "         [0.62352943],\n",
       "         ...,\n",
       "         [0.9529412 ],\n",
       "         [0.63529414],\n",
       "         [0.16078432]],\n",
       "\n",
       "        [[0.62352943],\n",
       "         [0.62352943],\n",
       "         [0.62352943],\n",
       "         ...,\n",
       "         [0.94509804],\n",
       "         [0.7019608 ],\n",
       "         [0.25490198]],\n",
       "\n",
       "        [[0.62352943],\n",
       "         [0.62352943],\n",
       "         [0.62352943],\n",
       "         ...,\n",
       "         [0.9607843 ],\n",
       "         [0.8       ],\n",
       "         [0.39607844]]],\n",
       "\n",
       "\n",
       "       [[[0.99607843],\n",
       "         [0.9882353 ],\n",
       "         [0.9843137 ],\n",
       "         ...,\n",
       "         [0.70980394],\n",
       "         [0.8039216 ],\n",
       "         [0.77254903]],\n",
       "\n",
       "        [[0.9882353 ],\n",
       "         [0.9843137 ],\n",
       "         [0.9764706 ],\n",
       "         ...,\n",
       "         [0.7372549 ],\n",
       "         [0.8117647 ],\n",
       "         [0.7647059 ]],\n",
       "\n",
       "        [[0.99215686],\n",
       "         [0.9882353 ],\n",
       "         [0.98039216],\n",
       "         ...,\n",
       "         [0.8117647 ],\n",
       "         [0.85882354],\n",
       "         [0.7882353 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         ...,\n",
       "         [0.8784314 ],\n",
       "         [0.8784314 ],\n",
       "         [0.8784314 ]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         ...,\n",
       "         [0.8784314 ],\n",
       "         [0.8784314 ],\n",
       "         [0.8784314 ]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         ...,\n",
       "         [0.8784314 ],\n",
       "         [0.8784314 ],\n",
       "         [0.8784314 ]]]], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=111)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNNを構築\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=X_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3))       # クラスは2個\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# コンパイル\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam',\n",
    "              metrics=['mean_squared_error'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0121 - val_mean_squared_error: 0.0121\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0121 - val_mean_squared_error: 0.0121\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0123 - val_mean_squared_error: 0.0123\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0122 - val_mean_squared_error: 0.0122\n",
      "Epoch 31/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
      "Epoch 32/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
      "Epoch 33/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
      "Epoch 34/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
      "Epoch 35/100\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
      "Epoch 36/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
      "Epoch 37/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
      "Epoch 38/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
      "Epoch 39/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
      "Epoch 40/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
      "Epoch 41/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
      "Epoch 42/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
      "Epoch 43/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
      "Epoch 44/100\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
      "Epoch 45/100\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
      "Epoch 46/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
      "Epoch 47/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
      "Epoch 48/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
      "Epoch 49/100\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
      "Epoch 50/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
      "Epoch 52/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
      "Epoch 53/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
      "Epoch 54/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
      "Epoch 55/100\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
      "Epoch 56/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
      "Epoch 57/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
      "Epoch 58/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
      "Epoch 59/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
      "Epoch 60/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
      "Epoch 61/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
      "Epoch 62/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
      "Epoch 63/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
      "Epoch 64/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
      "Epoch 65/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
      "Epoch 66/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
      "Epoch 67/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
      "Epoch 68/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
      "Epoch 69/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
      "Epoch 70/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
      "Epoch 71/100\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
      "Epoch 72/100\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
      "Epoch 73/100\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
      "Epoch 74/100\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
      "Epoch 75/100\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
      "Epoch 76/100\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
      "Epoch 77/100\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
      "Epoch 78/100\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
      "Epoch 79/100\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
      "Epoch 80/100\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
      "Epoch 81/100\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
      "Epoch 82/100\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
      "Epoch 83/100\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
      "Epoch 84/100\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
      "Epoch 85/100\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
      "Epoch 86/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
      "Epoch 87/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
      "Epoch 88/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
      "Epoch 89/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
      "Epoch 90/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
      "Epoch 91/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
      "Epoch 92/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
      "Epoch 93/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
      "Epoch 94/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
      "Epoch 95/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
      "Epoch 96/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
      "Epoch 97/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
      "Epoch 98/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
      "Epoch 99/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
      "Epoch 100/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n"
     ]
    }
   ],
   "source": [
    "# 実行。出力はなしで設定(verbose=0)。\n",
    "history = model.fit(X_train, y_train, batch_size=5, epochs=100,\n",
    "                   validation_data = (X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27247814370>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-ca87987486cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'epoch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'acc'"
     ]
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(['acc', 'val_acc'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.010550183244049549,\n",
       "  0.01034997683018446,\n",
       "  0.010326549410820007,\n",
       "  0.01035822182893753,\n",
       "  0.01032597478479147,\n",
       "  0.010316764935851097,\n",
       "  0.010382873006165028,\n",
       "  0.010176633484661579,\n",
       "  0.010243519209325314,\n",
       "  0.010239914059638977,\n",
       "  0.010151567868888378,\n",
       "  0.010236436501145363,\n",
       "  0.010263257659971714,\n",
       "  0.01014041993767023,\n",
       "  0.010175562463700771,\n",
       "  0.010297642089426517,\n",
       "  0.010224776342511177,\n",
       "  0.010271305218338966,\n",
       "  0.010143651627004147,\n",
       "  0.010085529647767544,\n",
       "  0.010250264778733253,\n",
       "  0.010207673534750938,\n",
       "  0.010083758272230625,\n",
       "  0.00999794714152813,\n",
       "  0.01006497535854578,\n",
       "  0.010059556923806667,\n",
       "  0.010216884315013885,\n",
       "  0.010228322818875313,\n",
       "  0.010235707275569439,\n",
       "  0.010214266367256641,\n",
       "  0.010312143713235855,\n",
       "  0.010242173448204994,\n",
       "  0.010157864540815353,\n",
       "  0.010121027007699013,\n",
       "  0.010066196322441101,\n",
       "  0.010075785219669342,\n",
       "  0.01003076508641243,\n",
       "  0.01014095637947321,\n",
       "  0.010055097751319408,\n",
       "  0.010138297453522682,\n",
       "  0.010059444233775139,\n",
       "  0.010040625929832458,\n",
       "  0.010097501799464226,\n",
       "  0.01005936786532402,\n",
       "  0.010026504285633564,\n",
       "  0.01002899743616581,\n",
       "  0.010036236606538296,\n",
       "  0.009998176246881485,\n",
       "  0.010137620382010937,\n",
       "  0.01009333599358797,\n",
       "  0.010148576460778713,\n",
       "  0.010086183436214924,\n",
       "  0.010065766982734203,\n",
       "  0.010121758095920086,\n",
       "  0.010039028711616993,\n",
       "  0.010051863268017769,\n",
       "  0.010084385983645916,\n",
       "  0.010038702748715878,\n",
       "  0.010046671144664288,\n",
       "  0.00997527688741684,\n",
       "  0.010088294744491577,\n",
       "  0.010028979741036892,\n",
       "  0.010013818740844727,\n",
       "  0.01004393957555294,\n",
       "  0.010045959614217281,\n",
       "  0.010077834129333496,\n",
       "  0.010055196471512318,\n",
       "  0.01000964269042015,\n",
       "  0.00998897384852171,\n",
       "  0.009973728097975254,\n",
       "  0.0100829703733325,\n",
       "  0.010036601684987545,\n",
       "  0.010063397698104382,\n",
       "  0.010065097361803055,\n",
       "  0.010176518000662327,\n",
       "  0.01012134924530983,\n",
       "  0.010000795125961304,\n",
       "  0.010079922154545784,\n",
       "  0.010160590521991253,\n",
       "  0.010032033547759056,\n",
       "  0.010135026648640633,\n",
       "  0.009974353946745396,\n",
       "  0.010068305768072605,\n",
       "  0.010104302316904068,\n",
       "  0.010066339746117592,\n",
       "  0.010055496357381344,\n",
       "  0.010015818290412426,\n",
       "  0.010130835697054863,\n",
       "  0.01028864923864603,\n",
       "  0.010131627321243286,\n",
       "  0.010006374679505825,\n",
       "  0.010043739341199398,\n",
       "  0.0100330775603652,\n",
       "  0.01006158348172903,\n",
       "  0.009973299689590931,\n",
       "  0.010028207674622536,\n",
       "  0.009980429895222187,\n",
       "  0.010017743334174156,\n",
       "  0.010030212812125683,\n",
       "  0.010038820095360279],\n",
       " 'mean_squared_error': [0.010550183244049549,\n",
       "  0.010349975898861885,\n",
       "  0.010326549410820007,\n",
       "  0.01035822182893753,\n",
       "  0.01032597478479147,\n",
       "  0.010316764935851097,\n",
       "  0.010382873006165028,\n",
       "  0.010176633484661579,\n",
       "  0.010243519209325314,\n",
       "  0.010239914059638977,\n",
       "  0.010151567868888378,\n",
       "  0.010236436501145363,\n",
       "  0.010263257659971714,\n",
       "  0.01014041993767023,\n",
       "  0.010175562463700771,\n",
       "  0.010297642089426517,\n",
       "  0.010224776342511177,\n",
       "  0.010271305218338966,\n",
       "  0.010143651627004147,\n",
       "  0.010085529647767544,\n",
       "  0.010250264778733253,\n",
       "  0.010207673534750938,\n",
       "  0.010083758272230625,\n",
       "  0.00999794714152813,\n",
       "  0.010064976289868355,\n",
       "  0.010059556923806667,\n",
       "  0.010216884315013885,\n",
       "  0.010228322818875313,\n",
       "  0.010235707275569439,\n",
       "  0.010214266367256641,\n",
       "  0.010312143713235855,\n",
       "  0.010242173448204994,\n",
       "  0.010157862678170204,\n",
       "  0.010121027007699013,\n",
       "  0.010066196322441101,\n",
       "  0.010075785219669342,\n",
       "  0.01003076508641243,\n",
       "  0.01014095637947321,\n",
       "  0.010055097751319408,\n",
       "  0.010138297453522682,\n",
       "  0.010059444233775139,\n",
       "  0.010040625929832458,\n",
       "  0.010097501799464226,\n",
       "  0.01005936786532402,\n",
       "  0.010026504285633564,\n",
       "  0.01002899743616581,\n",
       "  0.010036236606538296,\n",
       "  0.009998176246881485,\n",
       "  0.010137620382010937,\n",
       "  0.01009333599358797,\n",
       "  0.010148576460778713,\n",
       "  0.010086183436214924,\n",
       "  0.010065766982734203,\n",
       "  0.010121758095920086,\n",
       "  0.010039028711616993,\n",
       "  0.010051863268017769,\n",
       "  0.010084385983645916,\n",
       "  0.010038702748715878,\n",
       "  0.010046671144664288,\n",
       "  0.00997527688741684,\n",
       "  0.010088294744491577,\n",
       "  0.010028979741036892,\n",
       "  0.010013818740844727,\n",
       "  0.01004393957555294,\n",
       "  0.010045959614217281,\n",
       "  0.010077834129333496,\n",
       "  0.010055196471512318,\n",
       "  0.01000964269042015,\n",
       "  0.00998897384852171,\n",
       "  0.009973728097975254,\n",
       "  0.0100829703733325,\n",
       "  0.010036601684987545,\n",
       "  0.010063397698104382,\n",
       "  0.010065097361803055,\n",
       "  0.010176518000662327,\n",
       "  0.01012134924530983,\n",
       "  0.010000795125961304,\n",
       "  0.010079922154545784,\n",
       "  0.010160590521991253,\n",
       "  0.010032033547759056,\n",
       "  0.010135026648640633,\n",
       "  0.009974353946745396,\n",
       "  0.01006830483675003,\n",
       "  0.010104302316904068,\n",
       "  0.010066339746117592,\n",
       "  0.010055496357381344,\n",
       "  0.010015818290412426,\n",
       "  0.010130835697054863,\n",
       "  0.010288647376000881,\n",
       "  0.010131627321243286,\n",
       "  0.010006374679505825,\n",
       "  0.010043739341199398,\n",
       "  0.0100330775603652,\n",
       "  0.010061582550406456,\n",
       "  0.009973298758268356,\n",
       "  0.010028206743299961,\n",
       "  0.009980429895222187,\n",
       "  0.010017743334174156,\n",
       "  0.010030212812125683,\n",
       "  0.010038820095360279],\n",
       " 'val_loss': [0.011786706745624542,\n",
       "  0.011701553128659725,\n",
       "  0.011839142069220543,\n",
       "  0.011704666540026665,\n",
       "  0.01185548771172762,\n",
       "  0.011843198910355568,\n",
       "  0.011532127857208252,\n",
       "  0.01164452824741602,\n",
       "  0.011721818707883358,\n",
       "  0.011663396842777729,\n",
       "  0.01167304441332817,\n",
       "  0.011781108565628529,\n",
       "  0.011813320219516754,\n",
       "  0.011870035901665688,\n",
       "  0.011984148994088173,\n",
       "  0.011714144609868526,\n",
       "  0.01172784436494112,\n",
       "  0.011775584891438484,\n",
       "  0.011709661222994328,\n",
       "  0.012064862065017223,\n",
       "  0.011633430607616901,\n",
       "  0.011671050451695919,\n",
       "  0.011742993257939816,\n",
       "  0.01174074225127697,\n",
       "  0.011742202565073967,\n",
       "  0.011749573051929474,\n",
       "  0.01178826205432415,\n",
       "  0.012102765962481499,\n",
       "  0.012251771986484528,\n",
       "  0.012207967229187489,\n",
       "  0.011864501982927322,\n",
       "  0.011853598989546299,\n",
       "  0.011549970135092735,\n",
       "  0.011679738759994507,\n",
       "  0.011675018817186356,\n",
       "  0.011737346649169922,\n",
       "  0.011524849571287632,\n",
       "  0.011667107231914997,\n",
       "  0.011819266714155674,\n",
       "  0.011752726510167122,\n",
       "  0.011636024340987206,\n",
       "  0.011536415666341782,\n",
       "  0.011552320793271065,\n",
       "  0.01166004128754139,\n",
       "  0.01165955513715744,\n",
       "  0.011600011959671974,\n",
       "  0.01199531089514494,\n",
       "  0.01163165457546711,\n",
       "  0.011532243341207504,\n",
       "  0.011691324412822723,\n",
       "  0.011639242060482502,\n",
       "  0.011586669832468033,\n",
       "  0.012047352269291878,\n",
       "  0.0117427883669734,\n",
       "  0.011760719120502472,\n",
       "  0.011819093488156796,\n",
       "  0.01175091415643692,\n",
       "  0.011648963205516338,\n",
       "  0.011721612885594368,\n",
       "  0.011831410229206085,\n",
       "  0.011806931346654892,\n",
       "  0.011704089120030403,\n",
       "  0.011635664850473404,\n",
       "  0.011636811308562756,\n",
       "  0.011611673049628735,\n",
       "  0.011620667763054371,\n",
       "  0.01187807321548462,\n",
       "  0.011625859886407852,\n",
       "  0.011676063761115074,\n",
       "  0.011726444587111473,\n",
       "  0.01163298636674881,\n",
       "  0.011575853452086449,\n",
       "  0.011610724963247776,\n",
       "  0.011743225157260895,\n",
       "  0.011714417487382889,\n",
       "  0.011715567670762539,\n",
       "  0.011764050461351871,\n",
       "  0.011815695092082024,\n",
       "  0.011641165241599083,\n",
       "  0.011682547628879547,\n",
       "  0.011688793078064919,\n",
       "  0.01164004486054182,\n",
       "  0.011814878322184086,\n",
       "  0.011731353588402271,\n",
       "  0.01181434653699398,\n",
       "  0.011693169362843037,\n",
       "  0.011637748219072819,\n",
       "  0.01185847818851471,\n",
       "  0.011680899187922478,\n",
       "  0.011866236105561256,\n",
       "  0.011576770804822445,\n",
       "  0.011639326810836792,\n",
       "  0.011661041527986526,\n",
       "  0.01165220607072115,\n",
       "  0.011660280637443066,\n",
       "  0.011652976274490356,\n",
       "  0.011726430617272854,\n",
       "  0.011605455540120602,\n",
       "  0.01164127979427576,\n",
       "  0.01174372248351574],\n",
       " 'val_mean_squared_error': [0.011786706745624542,\n",
       "  0.011701553128659725,\n",
       "  0.011839142069220543,\n",
       "  0.011704666540026665,\n",
       "  0.01185548771172762,\n",
       "  0.011843198910355568,\n",
       "  0.011532127857208252,\n",
       "  0.01164452824741602,\n",
       "  0.011721818707883358,\n",
       "  0.011663396842777729,\n",
       "  0.011673043482005596,\n",
       "  0.011781108565628529,\n",
       "  0.011813320219516754,\n",
       "  0.011870035901665688,\n",
       "  0.011984148994088173,\n",
       "  0.011714144609868526,\n",
       "  0.01172784436494112,\n",
       "  0.011775584891438484,\n",
       "  0.011709661222994328,\n",
       "  0.012064862065017223,\n",
       "  0.011633430607616901,\n",
       "  0.011671051383018494,\n",
       "  0.011742993257939816,\n",
       "  0.01174074225127697,\n",
       "  0.011742202565073967,\n",
       "  0.011749573051929474,\n",
       "  0.01178826205432415,\n",
       "  0.012102765962481499,\n",
       "  0.012251771986484528,\n",
       "  0.012207967229187489,\n",
       "  0.011864501982927322,\n",
       "  0.011853598989546299,\n",
       "  0.011549970135092735,\n",
       "  0.011679738759994507,\n",
       "  0.011675018817186356,\n",
       "  0.011737346649169922,\n",
       "  0.011524849571287632,\n",
       "  0.011667107231914997,\n",
       "  0.011819266714155674,\n",
       "  0.011752726510167122,\n",
       "  0.011636024340987206,\n",
       "  0.011536415666341782,\n",
       "  0.011552320793271065,\n",
       "  0.011660042218863964,\n",
       "  0.01165955513715744,\n",
       "  0.011600011959671974,\n",
       "  0.01199531089514494,\n",
       "  0.01163165457546711,\n",
       "  0.011532243341207504,\n",
       "  0.011691324412822723,\n",
       "  0.011639242060482502,\n",
       "  0.011586669832468033,\n",
       "  0.012047352269291878,\n",
       "  0.0117427883669734,\n",
       "  0.011760719120502472,\n",
       "  0.011819093488156796,\n",
       "  0.01175091415643692,\n",
       "  0.011648963205516338,\n",
       "  0.011721612885594368,\n",
       "  0.011831410229206085,\n",
       "  0.011806931346654892,\n",
       "  0.011704089120030403,\n",
       "  0.011635664850473404,\n",
       "  0.011636811308562756,\n",
       "  0.011611673049628735,\n",
       "  0.011620667763054371,\n",
       "  0.01187807321548462,\n",
       "  0.011625859886407852,\n",
       "  0.011676063761115074,\n",
       "  0.011726444587111473,\n",
       "  0.01163298636674881,\n",
       "  0.011575853452086449,\n",
       "  0.011610724963247776,\n",
       "  0.011743225157260895,\n",
       "  0.011714417487382889,\n",
       "  0.011715567670762539,\n",
       "  0.011764050461351871,\n",
       "  0.011815695092082024,\n",
       "  0.011641165241599083,\n",
       "  0.011682547628879547,\n",
       "  0.011688793078064919,\n",
       "  0.01164004486054182,\n",
       "  0.011814878322184086,\n",
       "  0.011731353588402271,\n",
       "  0.011814345605671406,\n",
       "  0.011693169362843037,\n",
       "  0.011637748219072819,\n",
       "  0.01185847818851471,\n",
       "  0.011680899187922478,\n",
       "  0.011866236105561256,\n",
       "  0.011576770804822445,\n",
       "  0.011639326810836792,\n",
       "  0.011661041527986526,\n",
       "  0.01165220607072115,\n",
       "  0.011660280637443066,\n",
       "  0.011652976274490356,\n",
       "  0.011726430617272854,\n",
       "  0.011605455540120602,\n",
       "  0.01164127979427576,\n",
       "  0.01174372248351574]}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
